# Logan-Project-AI
Rice Plant Diseases Dataset을 사용한 모델 성능 비교

## 개요
본 실험은 CNN 모델을 활용하여 Rice Plant Diseases 데이터셋의 질병 분류 정확도를 높이는 튜닝 전략을 비교 평가하는 것을 목표로 한다. 데이터 증강 방법과 모델의 규모, 학습 방식에 따른 성능 차이를 확인한다.

### 실험 목표
- 데이터 증강이 모델 성능에 미치는 영향을 평가한다.
- 다양한 크기(대형부터 경량까지)의 모델에서 성능 변화를 분석한다.
- 학습 방식(특징 추출, 파인튜닝)에 따른 성능 차이를 분석한다.

## 데이터셋 설명
- Kaggle의 Rice Plant Diseases Dataset
- Brownspot, Leafsmut, Bacterialblight 3가지 종류로 구성
- 각 1620, 1460, 1604 장으로 균형이 양호한 편
- 모든 이미지는 300x300 픽셀의 해상도, JPG 형식으로 제공
![image](https://github.com/user-attachments/assets/abcb9751-1471-4b91-af43-59c329db99c4)


## 전처리 및 증강 방식
- 전처리 : trian, valid, test를 8:1:1로 분할
- 증강 : transforms.Compose 사용
  - 크기 변경 : 사이즈를 232로 변경하였다가 Crop을 통해 224로 통일
  - 뒤집기 : 수평 방향으로 랜덤 플립
  - 회전 : 30도 범위 내에서 랜덤 회전
  - 색상 변화 : 밝기와 대비를 조금 변화 (채도와 색조의 변화는 없음)

## 모델 및 학습 방식
### 사용 모델
- ResNet50: 대형 모델로 선정 (약 23M 파라미터)
- EfficientNet-B2: 중형 모델로 선정 (약 9.2M 파라미터)
- MobileNetV2: 경량 모델로 선정 (약 3.4M 파라미터)

### 학습 방식
- Feature Extraction: fc 레이어만 학습
- Partial Fine-Tuning: 상위 레이어의 1/4 정도를 해제하여 fc 레이어와 함께 학습
- Full Fine-Tuning: 모든 레이어를 해제하여 학습

## 실험 방법
조건에 해당하는 모델의 생성을 공통 함수로 생성하여 진행 (get_model 함수 참고)
  - 데이터 증강 여부 (원본 vs 증강 이미지)
  - 모델 규모 비교 (ResNet50 vs EfficientNet_b2 vs MobileNet_v2)
  - 학습 방식 비교 (feature extraction vs partial fine-tuning vs full fine-tuning)

위의 모델 후보 18개를 학습 진행 후, 최종 결과를 sqlite3 DB에 저장

## 실험 결과
1. 원본 데이터 vs 증강 데이터
- 원본 데이터의 경우 Feature Extract만 적용해도 99% 이상의 정확도 달성
- 증강 데이터를 사용하는 경우 Feature Extract에서 1.7% 정도의 성능 하락 발생, 나머지 방식들은 비슷한 성능
2. 모델 파라미터 규모에 따른 차이
- 파라미터가 많을수록 증강 데이터로 인한 성능 하락에 방어를 잘 하는 모습을 보임
- 일반화 능력이 경량 모델에 비해 대형 모델이 뛰어나다는 것으로 해석하였음
3. 학습 방식 변화에 따른 차이
- 기본적으로 unfreeze 레이어가 많아질수록 성능이 증갛하긴 하였으나 그 수치가 0.001% 내외로 적은 편이긴 하였음
- 준비된 데이터셋 자체가 크게 훼손된 부분이 없어서 모델의 학습이 잘 진행된 것으로 해석함
  
### Grad-CAM
번외로 Grad-CAM을 활용하여 모델의 분류 기준을 확인한 결과 대부분의 이미지는 잘 진행되었으나,<br>
특정 몇 개의 이미지(다른 잎이 함께 촬영, 혹은 손가락이 함께 촬영된 경우)에 대해서는 질병 부위가 아닌 배경에 집중하여 분류하는 모습을 보임<br>
분류 결과는 잘 나왔으나 잘못된 기준을 보인 것 같아 아쉬움이 남음<br>
전처리 과정에서 이런 부분들을 잘라서 처리하였으면 더 좋은 Grad-CAM 결과를 얻을 수 있을 것 같음

## 결론
이미지 데이터셋이 잘 준비된 환경에서 진행하여 큰 문제점이 발생하지 않고 잘 진행됨<br>
최초 기대한 바와 달리 증강 데이터에서 성능의 하락이 약간씩 있었으나, 그 수치가 매우 큰 편차를 보이지 않았고 여러 회차의 진행에서 유사하게 나타남<br>
결과를 통해 이미지에 대해 튜닝을 진행할 때 feature extract 방식에서 partial fine-tuning을 거치고 full fine-tuning으로 학습 소모 리소스를 증가하는 방식을 취해서, 적당한 합의점에서 학습을 진행시키는 것이 좋을 것 같다는 생각을 함<br>
